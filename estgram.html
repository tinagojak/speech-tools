<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>Edinburgh Speech Tools: Grammar</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="est.jpg"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Edinburgh Speech Tools
   &#160;<span id="projectnumber">2.1-release</span>
   </div>
  </td>
   <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('estgram.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Grammar </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="estgramoverview"></a>
Overview</h1>
<p>To aid speech recognition and general text processing the speech tools library provides an number of techniques to process various types of grammars.</p>
<p>These consist of a continuing expanding set of class and related programs. These are at various levels of development but all have fairly stable and working basic features.</p>
<h2><a class="anchor" id="estgramngrams"></a>
N-grams</h2>
<p>Ngram language models are supported by the <a class="el" href="classEST__Ngrammar.html">EST_Ngrammar</a> class, and associated routines and programs. Support is provided for building. tuning, smoothing and running n-gram models. N-grams themselves have been can be internally stored in either a <em>dense</em> or <em>sparse</em>. In the dense case all possible states are represented with probability distributions, while the sparece case only has those possible states for with data is available. Sparse will be much smaller in very large cases. However we consider the dense case to be the most fully developed.</p>
<p>Formally n-grams can be views as a special case of weighted finite state machines. Our implementation reflects that where possible (backoff options break this simple view), thus a start state is provided and traversal operation are given. This method of using n-grams is by far the most efficient as only one new piece of information is required at each stage, so no vectors of tokens need be collected (or shifted) and presented to n-gram class. However as this finite state machine view can't always be reasonable used we also support access through a vector of tokens.</p>
<h3><a class="anchor" id="estgramngrambuild"></a>
Building ngram language models</h3>
<p>The program <a class="el" href="ngram_build_manual.html">ngram_build</a> estimates ngram language models from data. The data can be in a number of formats and be saved in both an ascii (easier for humans to read) and binary (quick to load) format.</p>
<h4>Vocabularies</h4>
<p>The vocabulary of an ngram must be predefined. This is required to allow efficient internal representation. This implementation supports two vocabularies, one for the n-1 tokens in an ngram and one for the nth token as potentially this "predictee" could be from a different class. We also support the notion of out of vocabulary word, so any token found in the input data that is not in the vocabulary may be mapped to that token.</p>
<p>In build n-grams there are options on what to do with n-grams which contain out of vocabulary tokens. They may be mapped to te specifed out of vocabulary word, the ngram can be ignored or the whole sentence containing the out of vocabulary word can be ignored.</p>
<h4>ngram data input formats</h4>
<p>The input data can be in a number of formats depending on how much preprocessing you wish to do before building. The most basic form is to submit n-grams. That is n tokens, on each line. For example for a tri-gram model of phones it might look like </p><pre class="fragment">0 # a1 
# a1 f 
a1 f r 
f r i 
r i k 
i k aa1 
k aa1 n 
aa1 n @ 
</pre><p>In this case the data preparation stage most create each n-gram with the sigle stepping through the data at each stage. This format we call <code>ngram_per_line</code></p>
<p>A second format is <code>sentence_per_line</code> where each line of a file is a complete "sentence". Ngrams for each n-tuple will be automatically created and cumulated. In this case the input file might look like </p><pre class="fragment">a1 f r i k aa1 n @
ei1 b r @ h a m
</pre><p>In this mode, ngrams for the tokens at start of the sentence are created by using the token by defining a <code>prev_tag</code> (and if necessary a <code>prev_prev_tag</code>). Thus given the above sentence by line file, a <code>prev_tag</code> of "#" and a <code>prev_prev_tag</code> of "0". The first few tri-grams cumulated are </p><pre class="fragment">0 # a1
# a1 f
a1 f r
</pre><p>If the ngram size requires looking back further the <code>prev_prev_tag</code> is repeat indefinitely. Likewise an end_tag is appended to the end of every sentence too, (i.e. end of every line).</p>
<p>A third data input format is <code>sentence_per_file</code> where line breaks are no longer signficant and n-grams are create for all n-tuples in the file. The same special cases are treated for beginning and end of file as are for beginning and end of line in the sentence_per_line case.</p>
<h4>Smoothing and Backoff</h4>
<p>We support a number of different techniques to deal with lack of data in a training set.</p>
<p>Good Turing smoothing <a class="el" href="citelist.html#CITEREF_churchgale1991">[2]</a> is supported allowing smoothing on n-grams whose frequency is less than M. We also support <em>backoff</em> where the n-1 grams are (recursively) built to provide an estimation of probability distributions for unseen n-grams.</p>
<h3><a class="anchor" id="estngramtesting"></a>
Testing ngram language models</h3>
<p><a class="el" href="ngram_test_manual.html">ngram_test</a> computes language model entropy/perplexity on test data. The test data may be in any of the formats described above.</p>
<h2><a class="anchor" id="estngramscfg"></a>
SCFGs</h2>
<p>Stochastic context-free grammars are a version of context-free grammars with probabilities on rules. In this implementation we assume SCFGs are always in Chomsky Normal From (CNF) where rules may only be binary or unary branching. When binary, both daughters must be non-terminals and when unary, the daughter must be a terminal.</p>
<p>The implementation here is primarily based on <a class="el" href="citelist.html#CITEREF_pereira1992inside">[4]</a> thus allowing unsupervised training of SCFGs as well as allowing seeding with a bracketed corpus which can vastly reduce training time, and improve results. Training uses the inside-outside algorithm.</p>
<p>The support is split into four parts: making grammars, training grammars, testing grammars and parsing.</p>
<p>A grammar file consists of a set of rules. Each rule is a bracketed list of probability, nonterminal, followed by two nonterminals or one terminal. A simple example is </p><pre class="fragment">(0.5 S A D)
(0.5 S C B)
(0.79 B S C)
(0.21 B a)
(0.79 D S A)
(0.21 D b)
(1 A b)
(1 C a)
</pre><p>The mother non-terminal in the first rule is the distinguished symbol.</p>
<p>Grammars may be constructed by hand, by the program <a class="el" href="scfg_make_manual.html">scfg_make</a> or by some other external process. The program <a class="el" href="scfg_make_manual.html">scfg_make</a> constructs a full grammar given a list (or number of) terminals and nonterminals. The rules can be assigned equal probabilities or random ones. The "probabilities" may be actual probabilities or log probabilties. For example given a file <code>wp19</code> with a list of terminals, a grammar suitable for training with 15 non-terminals may be created by the command </p><pre class="fragment">scfg_make -nonterms 15 -terms wp19 -domain prob \
          -values random -o wsj_15_19.gram
</pre><p>The non-terminals or terminal names will be automatically generated if a number is given, or will be as specified if a file name is given. In the case of a filename being given, no brackets should be the file just whitespace separated tokens.</p>
<p>A corpus consists of a number of sentences, each sentence must be contain within a set of parenthesis. The sentences themselves may additionally contain further bracketing (for training and testing). Each sentence is read by the Lisp reader so comments (semi-colon to end of file) may be included. For example</p>
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;((((n n) punc ((cd n) j) punc)</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160; (md (v (dt n) (in (dt j n)) (n cd)))</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160; punc))</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;(((n n) (v ((n) (in ((n n) punc (dt n v n))))) punc))</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;((((n n) punc (((cd n) j) cc ((j n) (in (n n n n)))) punc)</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160; (v (v (((dt j n) (in (dt j j n))))))</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160; punc))</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;...</div></div><!-- fragment --><p>Training is done by estimating the inside and outside probabilities of the rules based on their current probabilities and a corpus. The corpus may optionally include internal bracketing which is used by the training algorithm to precluded some possible parses hence making the training typically faster (and sometimes more accurate). After each training pass the grammar rule probabilities are updated and the process starts again. Note depending on the number of training sentences training passes may take a very long time. After each passes the cross entropy for the current version of the grammar is printed. This should normally decrease until the the "best" grammar has been found.</p>
<p>The program <a class="el" href="scfg_train_manual.html">scfg_train</a> takes an initial grammar, and corpus and, by default will train for 100 passes. Because it can take prohibitively long for a desired number of passes an option is available to selection only an N percent chunk of the training set on each pass, cycling through the other N percent chunks of the corpus on each pass Experiments have shown that this not only produces much faster training, but the accuracy of the fully trained grammar is very similar. Given the choice of waiting taking 10 days or 48 hours to parse, it is highly recommended.</p>
<p>After each N passes the current state of the grammar may be saved, the number of passes between saving is specified by the <code>-checkpoint</code> option. The grammar is saved in the output file appended with the pass number.</p>
<p>Because the partitioned training will select different partitions depending on the pass number you can optionally specify the starting pass number, making it much easier to continue training after some interruption.</p>
<p>Testing is done by the program <a class="el" href="scfg_test_manual.html">scfg_test</a> it takes a grammar and a corpus. That corpus may be fully bracketed or not. By default the mean cross entropy value from anaylzing these senetences will be printed, also the number sentence sthat fail to parse.</p>
<p>Alternatively a <em>bracketing accuracy</em> may be calculated this is the percentage of prhases in a parsed sentence that are compatible with the bracketing in the corpus example.</p>
<p>The fourth program provides a mechanism for parsing one or more sentences. The corpus this time should contain no bracketing except around the beginning and end of the sentence itself. Two forms of parses are produced. A full form with start and end points for each phrase, the related non-terminal and the probability, and a simple form where only the bracketing is given. Note only one (or no) parses is given. For any phrase only the best example tree is given though the probability is given as the sum of all possibily derivations of that non-terminal for that phrase. </p><pre class="fragment">scfg_parse -grammar wsj_15_19.gram -corpus news.data -brackets -o news.out
</pre><p>Note the input for must be strings of terminals for the given grammar. For real parsing of real text it is likely the grmmar uses part of speech tags as terminals and the data is avtuall words not part of speech tags. If you want to parse texts then you can use the Festival script <code>festival/examples/scfg_parse_text</code> which takes in arbitrary text, runs the part of speech tagger on it after standard tokenizing rules and parses the output saving the parse to the specified file.</p>
<h2><a class="anchor" id="estngramwfst"></a>
WFSTs</h2>
<p>The speech tools contains a small, but growing library of basic functions for building, and manipulating weighted finite state transducers. Although not complete they already provided many of the basic operations and compilers one needs for using these devices.</p>
<p>Given a WFST the following operations are supported: deterimise, <a class="el" href="EST__WFST_8h.html#ad16e03fca88310ac26bd6725e63d151d">minimize</a>, <a class="el" href="EST__WFST_8h.html#ab4be69ec5978c68de8d6f4f0811d87d3">complement</a>.</p>
<p>Given two WFSTs the following operations are supported: intersection, union, <a class="el" href="EST__wave__temp_8cc.html#a76e12f4286e2727c1a8a153870991208">difference</a>, concatenation and <a class="el" href="EST__WFST_8h.html#a5f92e9fbdc522454f014659f81428327">compose</a>.</p>
<p>In addition to these operations compiles are provided for a number of basic input formats: regular expressions, regular grammars, context-free grammars (with depth restriction) and Kay/Kaplan/Koksenniemi two-level morphology rules.</p>
<p>Still missing are complete treatment of the weights through some basic operations (e.g. minimization doesn't presever weights). Also techniques for learning WFSTs from data, or at least weightign existing FSTs from data will be added in later versions.</p>
<p>In general inputing symbols is of the form X or X/Y. When X is given it is (except if using the wfst as a transducer) treated as X/X. Where X/Y is input/output symbols, thus using single symbols will mostly cause the wfst mechanisms to act as if they are finite state machines.</p>
<p>The two main programs are <a class="el" href="wfst_build_manual.html">wfst_build</a> and <a class="el" href="wfst_run_manual.html">wfst_run</a>. <a class="el" href="wfst_run_manual.html">wfst_run</a> runs in both recognition and transduction mode.</p>
<p>wfst_build_ builds wfst's from description files or through combination of existing ones. The output may be optionally determinized or determinized and minimized.</p>
<h3><a class="anchor" id="estngramwfstkaykaplan"></a>
Kay/Kaplan/Koskenniemi morphological rules</h3>
<p>One of the major drives in interest in wfst has been through their use in morphology <a class="el" href="citelist.html#CITEREF_kaplan94">[3]</a>. Hence we provide a method for compiling Kay/Kaplan/Koskenniemi type (restricted) context sensitive rewrite rules. The exact form is given in the example below.</p>
<p>This example covers basic letters to letters but also Epenthesis for e-insertion in words like <code>churches</code> and <code>boxes</code>. </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;(KKrules</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160; engmorph</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160; (Alphabets</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;  ;; Input Alphabet</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;  (a b c d e f g h i j k l m n o p q r s t u v w x y z #) </div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;  ;; Output Alphabet</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;  (a b c d e f g h i j k l m n o p q r s t u v w x y z + #) </div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160; )</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160; (Sets</div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;  (LET a b c d e f g h i j k l m n o p q r s t u v w x y z)</div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160; )</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160; (Rules</div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160; ;; The basic rules</div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160; ( a =&gt; nil --- nil) </div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160; ( b =&gt; nil --- nil) </div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160; ( c =&gt; nil --- nil) </div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160; ( d =&gt; nil --- nil) </div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160; ( e =&gt; nil --- nil) </div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160; ( f =&gt; nil --- nil) </div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160; ( g =&gt; nil --- nil) </div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160; ( h =&gt; nil --- nil) </div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160; ( i =&gt; nil --- nil) </div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160; ( j =&gt; nil --- nil) </div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160; ( k =&gt; nil --- nil) </div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160; ( l =&gt; nil --- nil) </div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160; ( m =&gt; nil --- nil) </div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160; ( n =&gt; nil --- nil) </div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160; ( o =&gt; nil --- nil) </div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160; ( p =&gt; nil --- nil) </div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160; ( q =&gt; nil --- nil) </div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160; ( r =&gt; nil --- nil) </div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160; ( s =&gt; nil --- nil) </div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160; ( t =&gt; nil --- nil) </div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160; ( u =&gt; nil --- nil) </div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160; ( v =&gt; nil --- nil) </div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160; ( w =&gt; nil --- nil) </div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160; ( x =&gt; nil --- nil) </div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160; ( y =&gt; nil --- nil) </div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160; ( z =&gt; nil --- nil) </div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160; ( # =&gt; nil --- nil)</div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160; ( _epsilon_/+ =&gt; (or LET _epsilon_/e) --- nil)</div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;</div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160; ;; Epenthesis</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160; ;;   churches -&gt; church+s</div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160; ;;   boxes -&gt; box+s</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160; (e/+ &lt;=&gt; (or (s h) (or s x z) (i/y) (c h))</div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;        ---</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;        (s))</div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;)</div></div><!-- fragment --><p>A substantially larger example of morphographenic rules is distributed with the Festival speech synthesis system in <code>festival/lib/engmorph.scm</code>. This is based on the English description in <b>[ritchie92]</b> .</p>
<p>For a definition of the semantics fo the basic types of rule, surface coercion, context restriction and combined rules see <b>[ritchie92]</b>. Note that these rules are run in parallel (the transducers are intersected) making they rule interact in ways that the author might not intend. A good rule debugger is really required in order to write a substantial set of rules in this formalism.</p>
<p>The rule compilation method used differs from Kay and Kaplan, and also from <b>[mohri96]</b> and actually follows them method used in <b>[ritchie92]</b> though in this case, unlike <b>[ritchie92]</b>, the technique is followed through to true wfst's. The actual compilation method shold be described somewhere.</p>
<p>The above may be compiled into a wfst by the command (assuming it is in the file <code>mm.rules</code>. </p><pre class="fragment">wfst_build -type kk -o engmorph.wfst -detmin engmorph.scm
</pre><p>This rule compiler has also been used in finding equivalent transducers for restricted forms of decision tree (following <b>[sproat96]</b>) and may be view as mostly stable.</p>
<h3><a class="anchor" id="estngramwfstregex"></a>
Regular expressions</h3>
<p>A simple method for building wfst's from regular expressions is also provided.</p>
<p>An example is </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;((a b c)</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;(a b c)</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;(and a (+ (or b c)) d))</div></div><!-- fragment --><p>This consists of the input alphabet and the output alphabet followed by a LISP s-expression contains the regex. The supported operators are <code>and</code>, <code>or</code>, <code>+</code>, <code>*</code> and <code>not</code>.</p>
<p>Compilation is by the following command: </p><pre class="fragment">wfst_build -type regex -o t1.wfst -detmin t1.regex
</pre><h3><a class="anchor" id="estngramwfstregulargrammars"></a>
Regular Grammars</h3>
<p>A compilation method also exists for regular grammars. These grammars do not need to be a normal form, in fact no chaeck is made that they are regular, if they contain center-embedding the construct algorithm will go into a loop and eventually run out of storage. The correction to that is to add a depth limit which would then allow wfst approximations of context-free grammars, which would be useful.</p>
<p>An example regular grammar is </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160; (RegularGrammar</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160; engsuffixmorphosyntax</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160; ;; Sets </div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160; (</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160; (V a e i o u y)</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160; (C b c d f g h j k l m n p q r s t v w x y z)</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160; )</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160; ;; Rules</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;</div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160; (</div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160; ;; A word *must* have a suffix to be recognized</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160; (Word -&gt; # Syls Suffix )</div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160; (Word -&gt; # Syls End )</div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;</div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160; ;; This matches any string of characters that contains at least one vowel</div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160; (Syls -&gt; Syl Syls )</div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160; (Syls -&gt; Syl )</div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160; (Syl -&gt; Cs V Cs )</div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160; (Cs -&gt; C Cs )</div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160; (Cs -&gt; )</div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;</div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160; (Suffix -&gt; VerbSuffix )</div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160; (Suffix -&gt; NounSuffix )</div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160; (Suffix -&gt; AdjSuffix )</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160; (VerbSuffix -&gt; VerbFinal End )</div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160; (VerbSuffix -&gt; VerbtoNoun NounSuffix )</div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160; (VerbSuffix -&gt; VerbtoNoun End )</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160; (VerbSuffix -&gt; VerbtoAdj  AdjSuffix )</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160; (VerbSuffix -&gt; VerbtoAdj End )</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160; (NounSuffix -&gt; NounFinal End )</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160; (NounSuffix -&gt; NountoNoun NounSuffix )</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160; (NounSuffix -&gt; NountoNoun End )</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160; (NounSuffix -&gt; NountoAdj AdjSuffix )</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160; (NounSuffix -&gt; NountoAdj End )</div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160; (NounSuffix -&gt; NountoVerb VerbSuffix )</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160; (NounSuffix -&gt; NountoVerb End )</div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160; (AdjSuffix -&gt; AdjFinal End )</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160; (AdjSuffix -&gt; AdjtoAdj AdjSuffix)</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160; (AdjSuffix -&gt; AdjtoAdj End)</div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160; (AdjSuffix -&gt; AdjtoAdv End)  ;; isn&#39;t any Adv to anything</div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;</div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160; (End -&gt; # )  ;; word boundary symbol *always* present</div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160; (VerbFinal -&gt; + e d)</div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160; (VerbFinal -&gt; + i n g)</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160; (VerbFinal -&gt; + s)</div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160; (VerbtoNoun -&gt; + e r)</div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160; (VerbtoNoun -&gt; + e s s)</div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160; (VerbtoNoun -&gt; + a t i o n)</div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160; (VerbtoNoun -&gt; + i n g)</div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160; (VerbtoNoun -&gt; + m e n t)</div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;</div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160; (VerbtoAdj -&gt; + a b l e)</div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;</div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160; (NounFinal -&gt; + s)</div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;</div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160; (NountoNoun -&gt; + i s m)</div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160; (NountoNoun -&gt; + i s t)</div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160; (NountoNoun -&gt; + s h i p)</div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;</div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160; (NountoAdj -&gt; + l i k e)</div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160; (NountoAdj -&gt; + l e s s)</div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160; (NountoAdj -&gt; + i s h)</div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160; (NountoAdj -&gt; + o u s)</div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160; (NountoVerb -&gt; + i f y)</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160; (NountoVerb -&gt; + i s e)</div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160; (NountoVerb -&gt; + i z e)</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160; (AdjFinal -&gt; + e r)</div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160; (AdjFinal -&gt; + e s t)</div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;</div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160; (AdjtoAdj -&gt; + i s h)</div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160; (AdjtoAdv -&gt; + l y)</div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160; (AdjtoNoun -&gt; + n e s s)</div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160; (AdjtoVerb -&gt; + i s e)</div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160; (AdjtoVerb -&gt; + i z e)</div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;</div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;)</div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;)</div></div><!-- fragment --><p>The above is a simple morpho-syntax for English.</p>
<h1><a class="anchor" id="estngramprograms"></a>
Programs</h1>
<p>The following are exectutable programs for grammars</p>
<ul>
<li>scfg_make_manual: make a set of rules for a SCFG.</li>
<li>scfg_train_manual: train a set of rules for a SCFG.</li>
<li>scfg_parse_manual: Perform parsing using pre-trained grammar</li>
<li>scfg_test_manual: Test the output of a parser.</li>
<li>wfst_build_manual: Build a weighted finite state transducer.</li>
<li>wfst_run_manual: Run a weighted finite state transducer.</li>
<li>ngram_build_manual: Train a n-gram from text.</li>
<li>ngram_test_manual: Calculate the perplexity etc of an n-gram.</li>
</ul>
<h1><a class="anchor" id="estngramclasses"></a>
Classes</h1>
<ul>
<li><a class="el" href="classEST__SCFG.html" title="A class representing a stochastic context free grammar (SCFG). ">EST_SCFG</a></li>
<li><a class="el" href="classEST__SCFG__Rule.html" title="A stochastic context free grammar rule. ">EST_SCFG_Rule</a></li>
<li><a class="el" href="classEST__SCFG__traintest.html" title="A class used to train (and test) SCFGs is an extension of EST_SCFG. ">EST_SCFG_traintest</a></li>
<li><a class="el" href="classEST__bracketed__string.html" title="This class represents a bracketed string used in training of SCFGs. ">EST_bracketed_string</a></li>
<li><a class="el" href="classEST__Ngrammar.html">EST_Ngrammar</a></li>
<li><a class="el" href="classEST__WFST.html" title="a call representing a weighted finite-state transducer ">EST_WFST</a> </li>
</ul>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Fri Oct 6 2017 18:25:30 for Edinburgh Speech Tools by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.11 </li>
  </ul>
</div>
</body>
</html>
